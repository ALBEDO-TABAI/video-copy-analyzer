# Video Copy Analyzer

[ä¸­æ–‡æ–‡æ¡£](README.zh-CN.md) | English

<div align="center">

**ğŸ¤– Claude Skill** | AI-Powered Video Analysis

[![Claude 4.5 Opus](https://img.shields.io/badge/Tested%20on-Claude%204.5%20Opus-blue)](https://claude.ai)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

> ğŸ¬ One-stop video content extraction and copywriting analysis tool. Download videos, smart subtitle extraction (embedded/burned/audio), and analyze scripts using three AI frameworks.

## âœ¨ Features

| Stage | Function | Description |
|-------|----------|-------------|
| 1ï¸âƒ£ | **Video Download** | Download from Bilibili/YouTube using yt-dlp |
| 2ï¸âƒ£ | **Smart Subtitle Extraction** | Three-tier priority: Embedded â†’ OCR (RapidOCR) â†’ ASR (FunASR/Whisper) |
| 3ï¸âƒ£ | **Smart Correction** | Context-based auto-correction of transcription errors |
| 4ï¸âƒ£ | **Three-Dimensional Analysis** | TextContent + Viral + Brainstorming |

## ğŸš€ Quick Start

### Prerequisites

```bash
# 1. yt-dlp (video downloader)
pip install yt-dlp

# 2. FFmpeg (must be installed and in PATH)
ffmpeg -version

# 3. Python dependencies
pip install pysrt python-dotenv

# 4. FunASR (Recommended for Chinese, lightweight & accurate)
pip install funasr modelscope

# 5. RapidOCR (ONNX lightweight, for burned subtitle detection)
pip install rapidocr-onnxruntime

# 6. Whisper (Alternative for English/multilingual)
pip install openai-whisper
```

### Usage

This is a **Claude Skill** designed for AI agents. Install it in your `.agent/skills/` directory:

```bash
git clone https://github.com/ALBEDO-TABAI/video-copy-analyzer.git .agent/skills/video-copy-analyzer
```

Then use it with Claude:

> "Analyze this video: https://www.bilibili.com/video/BV1xxxxx"

## ğŸ¯ Smart Subtitle Extraction (3-Tier Priority)

The skill automatically selects the best extraction method:

```
Video Input
    â†“
[1ï¸âƒ£ Embedded Subtitle] â”€â”€â†’ Detected â”€â”€â†’ Direct Extract (Highest Accuracy)
    â†“ Not detected
[2ï¸âƒ£ Burned Subtitle OCR] â”€â”€â†’ RapidOCR Frame Sampling â”€â”€â†’ Detected â”€â”€â†’ Full Video OCR
    â†“ Not detected
[3ï¸âƒ£ Audio Transcription] â”€â”€â†’ FunASR (Chinese optimized) / Whisper (Multilingual)
    â†“
Output SRT Subtitles
```

### Extraction Methods Comparison

| Tier | Method | Use Case | Accuracy | Speed |
|------|--------|----------|----------|-------|
| **L1** | Embedded Extract | Video has subtitle stream | â­â­â­â­â­ | âš¡ Fastest |
| **L2** | RapidOCR | Subtitles burned into video | â­â­â­â­ | ğŸš€ Fast |
| **L3** | FunASR Nano | Chinese audio transcription | â­â­â­â­ | ï¿½ Medium |
| **L3** | Whisper | English/multilingual audio | â­â­â­ | ğŸ¢ Medium |

### Tech Stack

- **RapidOCR (ONNX)**: Lightweight OCR for burned subtitle detection
  - ğŸš€ Lightweight: ONNX Runtime, no GPU required
  - ğŸ¯ Cross-platform: Windows/Linux/Mac
  - ğŸ“¦ Easy deploy: Single pip install
  - âœ¨ High accuracy: Based on PaddleOCR

- **FunASR Nano**: Alibaba open-source Chinese ASR model
  - ğŸš€ Lightweight: ~100MB vs Whisper Large ~1.5GB
  - ğŸ¯ Chinese optimized: Better than Whisper for Chinese
  - â±ï¸ Timestamp: Word-level timestamps
  - ğŸ’¨ Fast: Runs well on CPU

## ï¿½ğŸ“Š Three-Dimensional Analysis Framework

### 1. TextContent Analysis
- Narrative structure breakdown
- Rhetorical device identification
- Keyword extraction

### 2. Viral-Abstract-Script Framework
- **Viral-5D Diagnosis**: Hook / Emotion / Peaks / CTA / Social Currency
- Style positioning
- Optimization suggestions

### 3. Brainstorming Framework
- Core value decomposition
- 2-3 creative direction exploration
- Incremental verification points

## ğŸ“ Project Structure

```
video-copy-analyzer/
â”œâ”€â”€ SKILL.md                          # Core skill instructions
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_subtitle_funasr.py    # Smart subtitle extraction (FunASR + RapidOCR)
â”‚   â”œâ”€â”€ extract_subtitle.py           # Whisper-based extraction
â”‚   â”œâ”€â”€ transcribe_audio.py           # Audio transcription script
â”‚   â””â”€â”€ check_environment.py          # Environment verification
â””â”€â”€ references/
    â””â”€â”€ analysis-frameworks.md        # Analysis framework details
```

## ğŸ”§ Configuration

On first use, the skill will prompt you to set a default output directory:

- **Option A**: Use default `~/video-analysis/`
- **Option B**: Specify each time
- **Option C**: Set a fixed custom directory

## ğŸ“„ Output Files

After analysis, you'll receive:

| File | Content |
|------|---------|
| `{video_id}.mp4` | Original video |
| `{video_id}.srt` | Raw subtitles |
| `{video_id}_transcript.md` / `{video_id}_æ–‡å­—ç¨¿.md` | Corrected transcript |
| `{video_id}_analysis.md` / `{video_id}_åˆ†ææŠ¥å‘Š.md` | Three-dimensional analysis report |

## ğŸ¯ Supported Environments

This is a **Claude Skill** that works with AI coding assistants:

| Environment | Model | Status |
|-------------|-------|--------|
| **Antigravity** | Gemini 3 Pro | âœ… Supported |
| **Cursor** | Claude 4.5 Opus | âœ… **Tested & Recommended** |
| **Claude Code** | Claude 4.5 Opus | âœ… Supported |
| **Windsurf** | Any Claude model | âœ… Supported |
| **Trae** | Claude 3.5/4 | âœ… Supported |

> ğŸ’¡ **Best Performance**: Tested with **Claude 4.5 Opus**, achieving optimal results in transcription correction and three-dimensional analysis.

## ğŸ“ License

MIT License
